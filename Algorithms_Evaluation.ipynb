{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9cd33d-5140-491b-8fef-18d59edec58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np #for numerical operations\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "import pandas as pd  #for data manipulatio\n",
    "import seaborn as sns  # statistical data visualization\n",
    "import joblib  # For saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4aafa7-538a-4f8e-9fcd-460f0ec3cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Bunny_Data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac349b8b-b252-40ab-90fb-39fcf60970b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the first column to 'Identifier'\n",
    "dataset.rename(columns={dataset.columns[0]: 'Identifier'}, inplace=True)\n",
    "dataset['Healthy'] = dataset['Bunny_Data'].apply(lambda x: 1 if x < 20 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932cdc0-2c73-4992-a8c8-df767c5be98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Bunny_Data column\n",
    "dataset.drop(columns=['Bunny_Data'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced88537-243c-4943-837c-bc222f4af899",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7515571-e079-4d27-bafe-b4c4883ed6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target variable\n",
    "x = dataset[['Humidity_Data', 'Light_Data', 'Temperature_Data']].values\n",
    "y = dataset['Healthy'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7470fe8-d781-42ea-983c-66f46fab0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 100)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6acaf-5c1f-484a-b5fe-4fa15546fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36431ce0-7742-49c2-9497-29e3a4ff46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builing and Training the Model using the Logistic regression algorithm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  # Importing Logistic Regression from sklearn\n",
    "model = LogisticRegression()  # create logistic regression model\n",
    "model.fit(x_train, y_train)   # train the model with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87f4e7-f9dc-4551-beb8-6b667af72547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef - how much y increase with the increasement of one unit of x\n",
    "#intercept - value of y, when all x are o\n",
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b3b90-6eb9-441a-a399-50a5cf83b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "#Calculates the accuracy score, confusion matrix, and classification report to evaluate the model's performance. \n",
    "#Plots the confusion matrix using seaborn.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "#Uses the trained classifier to make predictions on the test data.\n",
    "y_pred = model.predict(x_test)\n",
    "comparison_df = pd.DataFrame({'Actual Y': y_test, 'Predicted Y': y_pred})\n",
    "print(comparison_df) # do  pd.Dataframe alone to get in table format\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy Score: {accuracy}')\n",
    "print(f'Accuracy Percentage: {accuracy * 100:.2f}%')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9808f-1000-49a2-9805-3d3fbaa6b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builing and Training the model using Support Vector algorithm\n",
    "from sklearn import svm\n",
    "model1 = svm.SVC(kernel='linear')  #create support vector machine model\n",
    "model1.fit(x_train, y_train)  #train the model with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace518c-8c12-44e9-91cb-88ba1c75c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "#Calculates the accuracy score, confusion matrix, and classification report to evaluate the model's performance. \n",
    "#Plots the confusion matrix using seaborn.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "#Uses the trained classifier to make predictions on the test data.\n",
    "y_pred_svm = model1.predict(x_test)\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "comparison_df_svm = pd.DataFrame({'Actual Y': y_test, 'Predicted Y': y_pred_svm})\n",
    "print(comparison_df_svm) # do  pd.Dataframe alone to get in table format\n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f'Accuracy Score: {accuracy_svm }')\n",
    "print(f'Accuracy Percentage: {accuracy_svm * 100:.2f}%')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_svm)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('SVM - Confusion Matrix')\n",
    "plt.show()\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c91be-4774-4dc3-ae72-ba83639aab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builing and Training the model using Decision Tree algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion='gini',\n",
    "                                   random_state=100,\n",
    "                                   max_depth=3, \n",
    "                                   min_samples_leaf=3)\n",
    "\n",
    "#Train the decision tree with training data\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494aabb2-5eb2-41e1-af2a-2d80520f1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots the trained Decision Tree to visualize its structure.\n",
    "plt.figure(figsize=(25,20))\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(classifier,\n",
    "          feature_names = ['Humidity_Data', 'Light_Data','Temperature_Data'],\n",
    "          class_names = ['Healthy','Not Healthy'],\n",
    "         filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4f996-c17a-4ac5-b961-3e44001da40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "#Calculates the accuracy score, confusion matrix, and classification report to evaluate the model's performance. \n",
    "#Plots the confusion matrix using seaborn.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "#Uses the trained classifier to make predictions on the test data.\n",
    "y_pred_dt = classifier.predict(x_test)\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "comparison_df_dt = pd.DataFrame({'Actual Y': y_test, 'Predicted Y': y_pred_dt})\n",
    "print(comparison_df_dt) \n",
    "print(\"\\n\")\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f'Accuracy Score: {accuracy_dt }')\n",
    "print(f'Accuracy Percentage: {accuracy_dt * 100:.2f}%')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_dt)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Decision Tree - Confusion Matrix')\n",
    "plt.show()\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ad50e-c873-41a1-9301-9c8bfb7b51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Upon evaluating the Logistic Regression algorithm, Support Vector algorithm, and the Decision Tree algorithm,\n",
    "it is prooven that the Decision Tree algorithm is the best to be deployed in this model, as it gives the \n",
    "highest accuracy rates. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e32195-7169-4833-9455-9d0b4864b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model and the scaler\n",
    "joblib.dump(classifier, 'decision_tree_model.pkl')\n",
    "joblib.dump(sc, 'scaler.pkl')\n",
    "print(\"Model and Scaler have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fec186-75f6-4c7b-8967-c7c17a366892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
